# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wGQhdPuMYrW_brLiRuh_21FXPQfNGEtH
"""

import math
import inspect
from dataclasses import dataclass
import torch
import torch.nn as nn
from torch.nn import functional as F
import numpy as np
import itertools
from transformers import AutoTokenizer
from datasets import load_dataset,DatasetDict,Dataset
from transformers import AutoTokenizer

# Keep existing helper functions (apply_rotary_position_embeddings, get_sinusoidal_embeddings)
# Adding new EncoderBlock class
def apply_rotary_position_embeddings(sinusoidal_pos, q, k):
    # Split the sinusoidal_pos into sin and cos parts
    sin, cos = sinusoidal_pos.chunk(2, dim=-1)
    # Apply the rotary embeddings to the query and key
    q_rot = torch.stack((-q[..., 1::2], q[..., ::2]), dim=-1)
    k_rot = torch.stack((-k[..., 1::2], k[..., ::2]), dim=-1)
    q_rot = torch.reshape(q_rot, q.shape[:-1] + (q.shape[-1]//2, 2)) * torch.stack((cos, sin), dim=-1)
    k_rot = torch.reshape(k_rot, k.shape[:-1] + (k.shape[-1]//2, 2)) * torch.stack((cos, sin), dim=-1)
    q_rot = torch.reshape(q_rot, q.shape)
    k_rot = torch.reshape(k_rot, k.shape)
    return q_rot, k_rot

def get_sinusoidal_embeddings( n_positions, dim):
    """Generate sinusoidal positional embeddings."""
    position = torch.arange(n_positions, dtype=torch.float).unsqueeze(1)
    div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))
    sinusoidal_emb = torch.zeros((n_positions, dim))
    sinusoidal_emb[:, 0::2] = torch.sin(position * div_term)
    sinusoidal_emb[:, 1::2] = torch.cos(position * div_term)
    return sinusoidal_emb
        
##########################
#N-transformer
#########################
#************************************************************************
class EncoderBlock(nn.Module):
    def __init__(self, config, iblock):
        super().__init__()
        self.config = config

        self.key = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.query = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.value = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.att_c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)

        self.c_fc = nn.Linear(config.n_embd, 2 * 4 * config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.silu = nn.SiLU()
        self.mlp_c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)

        if (config.use_nGPT == 0):
            self.rmsnorm_att = RMSNorm(config.n_embd)
            self.rmsnorm_mlp = RMSNorm(config.n_embd)

        if (config.use_nGPT == 1):
            self.attn_alpha = nn.Parameter(config.base_scale * torch.ones(config.n_embd))
            self.mlp_alpha = nn.Parameter(config.base_scale * torch.ones(config.n_embd))
            self.sqk = nn.Parameter(config.base_scale * torch.ones(config.n_embd))
            self.suv = nn.Parameter(torch.ones(2 * 4 * config.n_embd))

            self.attn_alpha_init_value = 0.05
            self.attn_alpha_init_scaling = config.base_scale
            self.mlp_alpha_init_value = 0.05
            self.mlp_alpha_init_scaling = config.base_scale
            self.sqk_init_value = 1.0
            self.sqk_init_scaling = config.base_scale
            self.suv_init_value = 1.0
            self.suv_init_scaling = 1.0

    def justnorm(self, x):
        return x / x.norm(p=2, dim=-1, keepdim=True)

    def forward(self, x, padding_mask=None):
        B, T, C = x.size()

        hin = x
        if (self.config.use_nGPT == 0):
            hin = self.rmsnorm_att(x)

        q = self.query(hin)
        k = self.key(hin)
        v = self.value(hin)

        q = q.view(B, T, self.config.n_head, C // self.config.n_head)
        k = k.view(B, T, self.config.n_head, C // self.config.n_head)
        v = v.view(B, T, self.config.n_head, C // self.config.n_head)

        sinusoidal_pos = get_sinusoidal_embeddings(T, C // self.config.n_head).to(device=q.device)
        q, k = apply_rotary_position_embeddings(sinusoidal_pos, q.transpose(1, 2), k.transpose(1, 2))
        q = q.transpose(2, 1)
        k = k.transpose(2, 1)

        if (self.config.use_nGPT == 1):
            sqk = (self.sqk * (self.sqk_init_value/self.sqk_init_scaling)).view(1, 1, self.config.n_head, C // self.config.n_head)
            q = sqk * self.justnorm(q)
            k = sqk * self.justnorm(k)

        q = q.transpose(1, 2)
        k = k.transpose(1, 2)
        v = v.transpose(1, 2)

        sqrt_head_dim = (C / self.config.n_head) ** 0.5
        softmax_scale = sqrt_head_dim if self.config.use_nGPT == 1 else 1.0 / sqrt_head_dim

        scores = torch.matmul(q, k.transpose(-2, -1)) * softmax_scale

        if padding_mask is not None:
            scores = scores.masked_fill(padding_mask[:, None, None, :] == 0, float('-inf'))

        attn_weights = F.softmax(scores, dim=-1)
        y = torch.matmul(attn_weights, v)

        y = y.transpose(1, 2).contiguous()
        y = y.view(B, T, C)
        h_att = self.att_c_proj(y)

        if (self.config.use_nGPT == 0):
            x = x + h_att
        if (self.config.use_nGPT == 1):
            lr = self.attn_alpha * (self.attn_alpha_init_value / self.attn_alpha_init_scaling)
            lr = torch.abs(lr)
            A_norm = self.justnorm(x)
            B_norm = self.justnorm(h_att)
            res = A_norm + lr * (B_norm - A_norm)
            x = self.justnorm(res)

        hin = x
        if (self.config.use_nGPT == 0):
            hin = self.rmsnorm_mlp(x)

        uv = self.c_fc(hin)
        if (self.config.use_nGPT == 1):
            suv = (self.suv * ((self.suv_init_value/self.suv_init_scaling) * (C ** 0.5)))
            uv = suv * uv

        u, v = torch.chunk(uv, 2, dim=-1)
        x_mlp = u * self.silu(v)
        h_mlp = self.mlp_c_proj(x_mlp)

        if (self.config.use_nGPT == 0):
            x = x + h_mlp
        if (self.config.use_nGPT == 1):
            lr = self.mlp_alpha * (self.mlp_alpha_init_value / self.mlp_alpha_init_scaling)
            lr = torch.abs(lr)
            A_norm = self.justnorm(x)
            B_norm = self.justnorm(h_mlp)
            res = A_norm + lr * (B_norm - A_norm)
            x = self.justnorm(res)

        return x

class RMSNorm(torch.nn.Module):
    def __init__(self, embdim: int, eps: float = 1e-6) -> None:
        super().__init__()
        self.weight = torch.nn.Parameter(torch.ones(embdim))
        self.eps = eps

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        dtype = x.dtype
        x = x.float()
        norm = torch.mean(x * x, dim=-1, keepdim=True)
        xnorm = x * torch.rsqrt(norm + self.eps)
        xnorm = xnorm.to(dtype=dtype)
        return xnorm * self.weight

class Block(nn.Module):
    def __init__(self, config, iblock):
        super().__init__()
        self.config = config

        # Self-attention
        self.key = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.query = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.value = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.att_c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)

        # Cross-attention
        self.cross_key = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.cross_query = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.cross_value = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.cross_c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)

        # FFN
        self.c_fc = nn.Linear(config.n_embd, 2 * 4 * config.n_embd, bias=config.bias, dtype=torch.bfloat16)
        self.silu = nn.SiLU()
        self.mlp_c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias, dtype=torch.bfloat16)

        if (config.use_nGPT == 0):
            self.rmsnorm_att = RMSNorm(config.n_embd)
            self.rmsnorm_cross = RMSNorm(config.n_embd)
            self.rmsnorm_mlp = RMSNorm(config.n_embd)

        if (config.use_nGPT == 1):
            self.attn_alpha = nn.Parameter(config.base_scale * torch.ones(config.n_embd))
            self.cross_attn_alpha = nn.Parameter(config.base_scale * torch.ones(config.n_embd))
            self.mlp_alpha = nn.Parameter(config.base_scale * torch.ones(config.n_embd))
            self.sqk = nn.Parameter(config.base_scale * torch.ones(config.n_embd))
            self.suv = nn.Parameter(torch.ones(2 * 4 * config.n_embd))

            # Initialize scaling values
            self.attn_alpha_init_value = 0.05
            self.attn_alpha_init_scaling = config.base_scale
            self.mlp_alpha_init_value = 0.05
            self.mlp_alpha_init_scaling = config.base_scale
            self.sqk_init_value = 1.0
            self.sqk_init_scaling = config.base_scale
            self.suv_init_value = 1.0
            self.suv_init_scaling = 1.0

    def justnorm(self, x):
        return x / x.norm(p=2, dim=-1, keepdim=True)

    def process_attention(self, q, k, v, mask=None, is_cross=False):
        B, H, L, D = q.size()  # batch, heads, length, dimension
        S = k.size(2)  # source sequence length

        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(D)

        if mask is not None:
            if isinstance(mask, tuple):
                # Self-attention masking
                causal_mask, padding_mask = mask
                if padding_mask is not None:
                    padding_mask = padding_mask.unsqueeze(1).unsqueeze(2)
                    padding_mask = padding_mask.expand(-1, H, L, S)
                    scores = scores.masked_fill(~padding_mask, float('-inf'))
                if causal_mask is not None and not is_cross:
                    scores = scores.masked_fill(causal_mask.unsqueeze(0).unsqueeze(0), float('-inf'))
            else:
                encoder_mask = mask.new_ones(B, S)  # Create a mask of ones for encoder sequence
                mask = encoder_mask.unsqueeze(1).unsqueeze(2)
                mask = mask.expand(-1, H, L, S)
                scores = scores.masked_fill(~mask, float('-inf'))

        attn_weights = F.softmax(scores, dim=-1)
        out = torch.matmul(attn_weights, v)

        return out

    def forward(self, x, encoder_out=None, causal_mask=None, padding_mask=None):
        B, T, C = x.size()

        # Self-attention
        hin = x if self.config.use_nGPT == 1 else self.rmsnorm_att(x)

        q = self.query(hin).view(B, T, self.config.n_head, C // self.config.n_head)
        k = self.key(hin).view(B, T, self.config.n_head, C // self.config.n_head)
        v = self.value(hin).view(B, T, self.config.n_head, C // self.config.n_head)

        sinusoidal_pos = get_sinusoidal_embeddings(T, C // self.config.n_head).to(device=q.device)
        q, k = apply_rotary_position_embeddings(sinusoidal_pos, q.transpose(1, 2), k.transpose(1, 2))
        q, k = q.transpose(2, 1), k.transpose(2, 1)

        if self.config.use_nGPT == 1:
            sqk = (self.sqk * (self.sqk_init_value/self.sqk_init_scaling)).view(1, 1, self.config.n_head, C // self.config.n_head)
            q = sqk * self.justnorm(q)
            k = sqk * self.justnorm(k)

        q, k, v = [x.transpose(1, 2) for x in (q, k, v)]

        # Self-attention with proper mask shapes
        y = self.process_attention(q, k, v, mask=(causal_mask, padding_mask))
        y = y.transpose(1, 2).contiguous().view(B, T, C)
        h_att = self.att_c_proj(y)

        if self.config.use_nGPT == 0:
            x = x + h_att
        else:
            lr = torch.abs(self.attn_alpha * (self.attn_alpha_init_value / self.attn_alpha_init_scaling))
            x = self.justnorm(self.justnorm(x) + lr * (self.justnorm(h_att) - self.justnorm(x)))

        # Cross-attention
        if encoder_out is not None:
            hin = x if self.config.use_nGPT == 1 else self.rmsnorm_cross(x)

            # Get encoder sequence length
            encoder_len = encoder_out.size(1)

            q = self.cross_query(hin).view(B, T, self.config.n_head, C // self.config.n_head)
            k = self.cross_key(encoder_out).view(B, encoder_len, self.config.n_head, C // self.config.n_head)
            v = self.cross_value(encoder_out).view(B, encoder_len, self.config.n_head, C // self.config.n_head)

            q, k, v = [x.transpose(1, 2) for x in (q, k, v)]
            # Cross-attention with padding mask only
            y = self.process_attention(q, k, v, mask=padding_mask, is_cross=True)
            y = y.transpose(1, 2).contiguous().view(B, T, C)
            h_cross = self.cross_c_proj(y)

            if self.config.use_nGPT == 0:
                x = x + h_cross
            else:
                lr = torch.abs(self.cross_attn_alpha * (self.attn_alpha_init_value / self.attn_alpha_init_scaling))
                x = self.justnorm(self.justnorm(x) + lr * (self.justnorm(h_cross) - self.justnorm(x)))

        # FFN
        hin = x if self.config.use_nGPT == 1 else self.rmsnorm_mlp(x)
        uv = self.c_fc(hin)

        if self.config.use_nGPT == 1:
            suv = self.suv * ((self.suv_init_value/self.suv_init_scaling) * (C ** 0.5))
            uv = suv * uv

        u, v = torch.chunk(uv, 2, dim=-1)
        x_mlp = u * self.silu(v)
        h_mlp = self.mlp_c_proj(x_mlp)

        if self.config.use_nGPT == 0:
            x = x + h_mlp
        else:
            lr = torch.abs(self.mlp_alpha * (self.mlp_alpha_init_value / self.mlp_alpha_init_scaling))
            x = self.justnorm(self.justnorm(x) + lr * (self.justnorm(h_mlp) - self.justnorm(x)))

        return x

@dataclass
class EncoderDecoderConfig:
    encoder_max_length: int = 512  # Max length for encoder sequences
    decoder_max_length: int = 256  # Max length for decoder sequences
    vocab_size: int = 50304
    n_layer: int = 12
    n_head: int = 12
    n_embd: int = 1024
    base_scale: float = 1.0 / (1024.0 ** 0.5)
    use_nGPT: int = 0
    dropout: float = 0.0
    bias: bool = False
    pad_token_id: int = 0
    block_size: int = 1024

class EncoderDecoderGPT(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.config = config

        # Encoder
        self.encoder = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            drop = nn.Dropout(config.dropout),
            h = nn.ModuleList([EncoderBlock(config, il) for il in range(config.n_layer)])
        ))

        # Decoder (using existing Block class)
        self.decoder = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            drop = nn.Dropout(config.dropout),
            h = nn.ModuleList([Block(config, il) for il in range(config.n_layer)])
        ))

        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)

        # Initialize
        self.apply(self._init_weights)
        for pn, p in self.named_parameters():
            if pn.endswith('c_proj.weight'):
                torch.nn.init.normal_(p, mean=0.0, std=config.base_scale/math.sqrt(2 * config.n_layer))
        # report number of parameters
        print("number of parameters: %.2fM" % (self.get_num_params()/1e6,))
        if (config.use_nGPT == 1):
            self.sz = nn.Parameter(self.config.base_scale * torch.ones(config.vocab_size))
            self.sz_init_value = 1.00
            self.sz_init_scaling = config.base_scale

        if (config.use_nGPT == 0):
            self.rmsnorm_f = RMSNorm(config.n_embd)

    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            torch.nn.init.normal_(module.weight, mean=0.0, std=self.config.base_scale)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Embedding):
            torch.nn.init.normal_(module.weight, mean=0.0, std=self.config.base_scale)

    def get_num_params(self, non_embedding=True):
        """
        Return the number of parameters in the model.
        For non-embedding count (default), the position embeddings get subtracted.
        The token embeddings would too, except due to the parameter sharing these
        params are actually used as weights in the final layer, so we include them.
        """
        n_params = sum(p.numel() for p in self.parameters())
        #if non_embedding:
        #    n_params -= self.transformer.wpe.weight.numel()
        return n_params

    def forward(self, enc_idx, dec_idx, targets=None, enc_mask=None, dec_mask=None, causal_mask=None):
        device = enc_idx.device

        # Encoder forward pass
        enc_embeddings = self.encoder.wte(enc_idx)
        enc_x = self.encoder.drop(enc_embeddings)

        # Apply encoder blocks
        for block in self.encoder.h:
            enc_x = block(enc_x, padding_mask=enc_mask)

        # Decoder forward pass
        dec_embeddings = self.decoder.wte(dec_idx)
        dec_x = self.decoder.drop(dec_embeddings)

        # Apply decoder blocks with cross-attention
        for block in self.decoder.h:
            dec_x = block(dec_x, encoder_out=enc_x, causal_mask=causal_mask, padding_mask=dec_mask)

        if self.config.use_nGPT == 0:
            dec_x = self.rmsnorm_f(dec_x)

        # Get logits
        logits = self.lm_head(dec_x)
        if self.config.use_nGPT == 1:
            sz = self.sz * (self.sz_init_value/self.sz_init_scaling)
            logits = sz * logits

        # Compute loss
        if targets is not None:
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)),
                                 targets.view(-1),
                                 ignore_index=self.config.pad_token_id)
        else:
            loss = None

        return logits, loss

    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):
        # Same as original implementation
        param_dict = {pn: p for pn, p in self.named_parameters() if p.requires_grad}
        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]
        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]
        optim_groups = [
            {'params': decay_params, 'weight_decay': weight_decay},
            {'params': nodecay_params, 'weight_decay': 0.0}
        ]
        num_decay_params = sum(p.numel() for p in decay_params)
        num_nodecay_params = sum(p.numel() for p in nodecay_params)
        print(f"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters")
        print(f"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters")
        # Create AdamW optimizer and use the fused version if it is available
        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters
        use_fused = False#fused_available and device_type == 'cuda'
        extra_args = dict(fused=True) if use_fused else dict()
        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)
        print(f"using fused AdamW: {use_fused}")
        return optimizer
#************************************************************************

# Data loading and preprocessing
def get_owt_dataset(block_size):
    """Load and preprocess OpenWebText dataset for encoder-decoder language modeling."""
    tokenizer = AutoTokenizer.from_pretrained("google-t5/t5-large")
    num_cpus = os.cpu_count()//2
    print(f"Using {num_cpus} CPUs")

    ds = load_dataset("Skylion007/openwebtext",split="train", num_proc=num_cpus,trust_remote_code=True).select(range(4000000))

    def tokenize_and_chunk(examples, tokenizer, block_size):
        """
        Tokenize and chunk text with dynamic sequence lengths based on block_size.
        Encoder length = block_size
        Decoder length = block_size // 2
        """
        encoder_max_len = block_size
        decoder_max_len = block_size // 2

        # Tokenize the text
        tokenized = tokenizer(
            examples["text"],
            truncation=True,
            max_length=encoder_max_len + decoder_max_len,  # Total length needed
            padding=False,
            return_tensors=None,
        )

        encoder_inputs = []
        decoder_inputs = []
        labels = []

        for input_ids in tokenized["input_ids"]:
            # Split into encoder and decoder parts
            encoder_part = input_ids[:encoder_max_len]
            decoder_part = input_ids[encoder_max_len:encoder_max_len + decoder_max_len]

            # Pad encoder sequence if needed
            if len(encoder_part) < encoder_max_len:
                padding_length = encoder_max_len - len(encoder_part)
                encoder_part = encoder_part + [tokenizer.pad_token_id] * padding_length

            # Only process if we have enough tokens for decoder (at least 2 tokens)
            if len(decoder_part) >= 2:
                # Create decoder input (all except last token) and labels (all except first token)
                decoder_input = decoder_part[:-1]
                label = decoder_part[1:]

                # Pad decoder sequences if needed
                if len(decoder_input) < decoder_max_len - 1:  # -1 because we removed last token
                    padding_length = (decoder_max_len - 1) - len(decoder_input)
                    decoder_input = decoder_input + [tokenizer.pad_token_id] * padding_length
                    label = label + [tokenizer.pad_token_id] * padding_length

                encoder_inputs.append(encoder_part)
                decoder_inputs.append(decoder_input)
                labels.append(label)

        return {
            "encoder_input_ids": encoder_inputs,
            "decoder_input_ids": decoder_inputs,
            "labels": labels
        }

    tokenized_ds = ds.map(
        lambda x: tokenize_and_chunk(x, tokenizer, block_size=block_size),
        batched=True,
        batch_size=30000,
        num_proc=num_cpus,
        remove_columns=ds.column_names,
    )

    return tokenized_ds, tokenizer

import os
import time
import math
import torch
from tqdm import tqdm, trange
import matplotlib.pyplot as plt
import wandb
from contextlib import nullcontext

class ModelAnalyzer:
    def __init__(self, model):
        self.model = model
        self.last_wandb_step = -1

    def compute_condition_number(self, matrix):
        try:
            U, S, V = torch.svd(matrix.float())
            return S[0].item() / S[-1].item()
        except:
            return float('nan')

    def save_figure(self, fig, name, iter_num, wandb_log=False):
        os.makedirs('plots', exist_ok=True)
        filepath = f'plots/analysis_{name}_{iter_num}.png'
        fig.savefig(filepath)
        if wandb_log:
            # Ensure we're using the current wandb step
            current_step = wandb.run.step if wandb.run else iter_num
            self.last_wandb_step = max(current_step, self.last_wandb_step)
            wandb.log({f'plot_{name}': wandb.Image(filepath)}, step=self.last_wandb_step)
        plt.close(fig)

    def analyze_qkv_matrices(self, block, layer_idx, component, iter_num, wandb_log=False):
        matrices = {
            'query': block.query.weight.data,
            'key': block.key.weight.data,
            'value': block.value.weight.data
        }

        stat_key = f'{component}_qkv_stats'
        if not hasattr(self, stat_key):
            setattr(self, stat_key, {name: [] for name in matrices.keys()})

        stats = getattr(self, stat_key)
        for name, matrix in matrices.items():
            cond_num = self.compute_condition_number(matrix)
            stats[name].append(cond_num)

        if layer_idx == len(getattr(self.model, component).h) - 1:
            fig = plt.figure(figsize=(10, 6))
            for name in matrices.keys():
                plt.plot(stats[name], label=name.capitalize())
            plt.xlabel('Layer')
            plt.ylabel('Condition Number')
            plt.yscale('log')
            plt.title(f'{component.capitalize()} Q/K/V Matrix Condition Numbers')
            plt.legend()
            plt.tight_layout()

            self.save_figure(fig, f'{component}_qkv_condition', iter_num, wandb_log)

    def analyze_mlp_layer(self, block, layer_idx, component, iter_num, wandb_log=False):
            """Analyze condition numbers of first, middle and last MLP layers"""
            if not hasattr(block, 'c_fc'):
                return

            total_layers = len(getattr(self.model, component).h)
            middle_layer_idx = total_layers // 2

            # Only collect stats for first, middle, and last layers
            stat_key = f'{component}_mlp_conds'
            if not hasattr(self, stat_key):
                setattr(self, stat_key, {
                    'first': None,
                    'middle': None,
                    'last': None
                })

            stats = getattr(self, stat_key)

            # Get condition number of the MLP feed-forward layer
            cond_num = self.compute_condition_number(block.c_fc.weight.data)

            # Store condition number for appropriate layer
            if layer_idx == 0:
                stats['first'] = cond_num
            elif layer_idx == middle_layer_idx:
                stats['middle'] = cond_num
            elif layer_idx == total_layers - 1:
                stats['last'] = cond_num

                # Create plot when we have all the data
                if all(v is not None for v in stats.values()):
                    fig = plt.figure(figsize=(10, 6))
                    layers = ['First', 'Middle', 'Last']
                    values = [stats['first'], stats['middle'], stats['last']]

                    plt.bar(layers, values)
                    plt.xlabel('Layer Position')
                    plt.ylabel('Condition Number')
                    plt.yscale('log')  # Using log scale for condition numbers
                    plt.title(f'{component.capitalize()} MLP Layer Condition Numbers')
                    plt.tight_layout()

                    self.save_figure(fig, f'{component}_mlp_analysis', iter_num, wandb_log)

    def analyze_scaling(self, block, layer_idx, component, iter_num, wandb_log=False):
        if not hasattr(block, 'sqk'):
            return

        stat_key = f'{component}_scaling_values'
        if not hasattr(self, stat_key):
            setattr(self, stat_key, {'sqk': [], 'su': [], 'sv': []})

        stats = getattr(self, stat_key)
        stats['sqk'].append(block.sqk.mean().item())
        su, sv = torch.chunk(block.suv, 2, dim=0)
        stats['su'].append(su.mean().item())
        stats['sv'].append(sv.mean().item())

        if layer_idx == len(getattr(self.model, component).h) - 1:
            fig = plt.figure(figsize=(15, 5))
            titles = ['Scaling sqk', 'Scaling su', 'Scaling sv']
            for i, (key, values) in enumerate(stats.items()):
                plt.subplot(1, 3, i+1)
                plt.title(f'{component.capitalize()} {titles[i]}')
                plt.xlabel('Layer')
                plt.ylabel('Value')
                plt.plot(values)
            plt.tight_layout()

            self.save_figure(fig, f'{component}_scaling_analysis', iter_num, wandb_log)

    def analyze_learning_rates(self, block, layer_idx, component, iter_num, wandb_log=False):
        if not (hasattr(block, 'attn_alpha') and hasattr(block, 'mlp_alpha')):
            return

        stat_key = f'{component}_lr_values'
        if not hasattr(self, stat_key):
            setattr(self, stat_key, {'attn': [], 'mlp': []})

        stats = getattr(self, stat_key)
        stats['attn'].append(block.attn_alpha.mean().item())
        stats['mlp'].append(block.mlp_alpha.mean().item())

        if layer_idx == len(getattr(self.model, component).h) - 1:
            fig = plt.figure(figsize=(10, 5))
            titles = ['Attention Learning Rates', 'MLP Learning Rates']
            for i, (key, values) in enumerate(stats.items()):
                plt.subplot(1, 2, i+1)
                plt.title(f'{component.capitalize()} {titles[i]}')
                plt.xlabel('Layer')
                plt.ylabel('Value')
                plt.plot(values)
            plt.tight_layout()

            self.save_figure(fig, f'{component}_lr_analysis', iter_num, wandb_log)

    def analyze_embedding_norms(self, iter_num, wandb_log=False):
        """Analyze the distribution of norms for input and output embeddings"""
        input_emb = self.model.encoder.wte.weight.data
        output_emb = self.model.decoder.wte.weight.data

        # Calculate norms
        input_norms = torch.norm(input_emb, dim=1).cpu().numpy()
        output_norms = torch.norm(output_emb, dim=1).cpu().numpy()

        # Sort norms and create normalized ranks
        sorted_input_norms = np.sort(input_norms)
        sorted_output_norms = np.sort(output_norms)
        n_input = len(input_norms)
        n_output = len(output_norms)
        norm_ranks_input = np.arange(n_input) / (n_input - 1)
        norm_ranks_output = np.arange(n_output) / (n_output - 1)

        # Create figure
        fig = plt.figure(figsize=(12, 5))

        # Input embeddings plot
        plt.subplot(1, 2, 1)
        plt.plot(norm_ranks_input, sorted_input_norms)
        plt.xlabel('Normalized Rank')
        plt.ylabel('Norm Value')
        plt.title('Distribution of Input Embedding Norms')

        # Output embeddings plot
        plt.subplot(1, 2, 2)
        plt.plot(norm_ranks_output, sorted_output_norms)
        plt.xlabel('Normalized Rank')
        plt.ylabel('Norm Value')
        plt.title('Distribution of Output Embedding Norms')

        plt.tight_layout()
        self.save_figure(fig, 'embedding_norms', iter_num, wandb_log)

    def analyze_embedding_eigenvalues(self, iter_num, wandb_log=False):
            """Analyze the distribution of eigenvalues for input and output embeddings"""
            def compute_eigenvalues_safely(embeddings):
                # Move to CPU to avoid GPU memory issues
                embeddings_cpu = embeddings.cpu()

                # Compute covariance matrix in chunks
                chunk_size = 1024  # Adjust this based on available CPU memory
                n_chunks = (embeddings_cpu.shape[0] + chunk_size - 1) // chunk_size
                cov = torch.zeros((embeddings_cpu.shape[1], embeddings_cpu.shape[1]))

                for i in range(n_chunks):
                    start_idx = i * chunk_size
                    end_idx = min((i + 1) * chunk_size, embeddings_cpu.shape[0])
                    chunk = embeddings_cpu[start_idx:end_idx]
                    cov += torch.mm(chunk.t(), chunk)

                # Compute eigenvalues
                try:
                    eigenvalues = torch.linalg.eigvalsh(cov)
                    return eigenvalues.numpy()
                except:
                    # Fallback to numpy if torch fails
                    return np.linalg.eigvalsh(cov.numpy())

            # Get embeddings
            input_emb = self.model.encoder.wte.weight.data
            output_emb = self.model.decoder.wte.weight.data

            # Calculate eigenvalues safely
            input_eigenvalues = compute_eigenvalues_safely(input_emb)
            output_eigenvalues = compute_eigenvalues_safely(output_emb)

            # Sort eigenvalues and normalize by median
            sorted_input_eigen = np.sort(input_eigenvalues)[::-1]  # Descending order
            sorted_output_eigen = np.sort(output_eigenvalues)[::-1]  # Descending order

            input_median = np.median(sorted_input_eigen)
            output_median = np.median(sorted_output_eigen)

            norm_input_eigen = sorted_input_eigen / input_median
            norm_output_eigen = sorted_output_eigen / output_median

            # Create normalized ranks
            n_input = len(input_eigenvalues)
            n_output = len(output_eigenvalues)
            norm_ranks_input = np.arange(n_input) / (n_input - 1)
            norm_ranks_output = np.arange(n_output) / (n_output - 1)

            # Create figure
            fig = plt.figure(figsize=(12, 5))

            # Input embeddings plot
            plt.subplot(1, 2, 1)
            plt.plot(norm_ranks_input, norm_input_eigen)
            plt.xlabel('Normalized Rank')
            plt.ylabel('Eigenvalue / median(Eigenvalues)')
            plt.title('Sorted Eigenvalues of Input Embeddings')
            plt.yscale('log')

            # Output embeddings plot
            plt.subplot(1, 2, 2)
            plt.plot(norm_ranks_output, norm_output_eigen)
            plt.xlabel('Normalized Rank')
            plt.ylabel('Eigenvalue / median(Eigenvalues)')
            plt.title('Sorted Eigenvalues of Output Embeddings')
            plt.yscale('log')

            plt.tight_layout()
            self.save_figure(fig, 'embedding_eigenvalues', iter_num, wandb_log)

    def analyze_embedding_dot_products(self, iter_num, wandb_log=False):
        """Analyze the distribution of pairwise dot products for input and output embeddings"""
        input_emb = self.model.encoder.wte.weight.data
        output_emb = self.model.decoder.wte.weight.data

        # Normalize embeddings
        input_emb_norm = input_emb / torch.norm(input_emb, dim=1, keepdim=True)
        output_emb_norm = output_emb / torch.norm(output_emb, dim=1, keepdim=True)

        # Calculate pairwise dot products
        input_dots = torch.mm(input_emb_norm, input_emb_norm.t())
        output_dots = torch.mm(output_emb_norm, output_emb_norm.t())

        # Get upper triangle values (excluding diagonal)
        input_dots_triu = input_dots.triu(diagonal=1).cpu().numpy()
        output_dots_triu = output_dots.triu(diagonal=1).cpu().numpy()

        input_dots_flat = input_dots_triu[input_dots_triu != 0]
        output_dots_flat = output_dots_triu[output_dots_triu != 0]

        # Sort values and create normalized ranks
        sorted_input_dots = np.sort(input_dots_flat)
        sorted_output_dots = np.sort(output_dots_flat)

        n_input = len(input_dots_flat)
        n_output = len(output_dots_flat)
        norm_ranks_input = np.arange(n_input) / (n_input - 1)
        norm_ranks_output = np.arange(n_output) / (n_output - 1)

        # Create figure
        fig = plt.figure(figsize=(12, 5))

        # Input embeddings plot
        plt.subplot(1, 2, 1)
        plt.plot(norm_ranks_input, sorted_input_dots)
        plt.xlabel('Normalized Rank')
        plt.ylabel('Dot Product Value')
        plt.title('Pairwise Dot Products of Input Embeddings')

        # Output embeddings plot
        plt.subplot(1, 2, 2)
        plt.plot(norm_ranks_output, sorted_output_dots)
        plt.xlabel('Normalized Rank')
        plt.ylabel('Dot Product Value')
        plt.title('Pairwise Dot Products of Output Embeddings')

        plt.tight_layout()
        self.save_figure(fig, 'embedding_dot_products', iter_num, wandb_log)

    def analyze_model(self, use_nGPT, iter_num, wandb_log=False):
        # Existing analysis
        if wandb_log:
            self.last_wandb_step = wandb.run.step if wandb.run else iter_num
        for component in ['encoder', 'decoder']:
            for i, block in enumerate(getattr(self.model, component).h):
                self.analyze_qkv_matrices(block, i, component, iter_num, wandb_log)
                self.analyze_mlp_layer(block, i, component, iter_num, wandb_log)

                if use_nGPT:
                    self.analyze_scaling(block, i, component, iter_num, wandb_log)
                    self.analyze_learning_rates(block, i, component, iter_num, wandb_log)

        # New embedding analyses
        self.analyze_embedding_norms(iter_num, wandb_log)
        self.analyze_embedding_eigenvalues(iter_num, wandb_log)
        self.analyze_embedding_dot_products(iter_num, wandb_log)


import os
import time
import math
import torch
from tqdm import tqdm,trange
from torch.nn import functional as F
import numpy as np
import wandb
from contextlib import nullcontext

# Training hyperparameters
eval_interval = 100
log_interval = 1
eval_iters = 200
eval_only = False
always_save_checkpoint = True
init_from = 'scratch'
wandb_log = True
wandb_project = 'owt'
wandb_run_name = 'ntransformer'
gradient_accumulation_steps = 64
batch_size = 16
dropout = 0.1
bias = False
max_iters = 2000
beta1 = 0.9
beta2 = 0.95
grad_clip = 1.0
decay_lr = True
lr_decay_iters = 1600
device = 'cuda'
dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'
compile = False
time_limit_seconds = 1000000000
max_iters_per_launch = 1000000000
test_size=0.0005
seed=42

use_nGPT = 1
learning_rate = 15e-4

# Model configuration
n_layer = 24
n_head = 16
n_embd = 1152
block_size = 1024

if use_nGPT == 0:
    min_lr = 0.0
    weight_decay = 0.1
    # warmup_iters = int(max_iters * (max_iters / 600000)) 
    warmup_iters = 100
else:
    min_lr = learning_rate / 10
    weight_decay = 0.0
    warmup_iters = 50

base_scale = 1.0 / n_embd ** 0.5 if use_nGPT == 1 else 0.02

# Initialize device and dtype settings
device_type = 'cuda' if 'cuda' in device else 'cpu'
ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]
ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)
if wandb_log:
    wandb.init(project=wandb_project, name=wandb_run_name, config={
        'learning_rate': learning_rate,
        'n_layer': n_layer,
        'n_head': n_head,
        'n_embd': n_embd,
        'block_size': block_size,
        'batch_size': batch_size
    })
train_losses = []
val_losses = []
iterations = []

def save_checkpoint(model, optimizer, iter_num, train_losses, val_losses, iterations, filename='checkpoint.pt'):
    checkpoint = {
        'model': model.state_dict(),
        'optimizer': optimizer.state_dict(),
        'model_args': {
            'use_nGPT': model.config.use_nGPT,
            'n_layer': model.config.n_layer,
            'n_head': model.config.n_head,
            'n_embd': model.config.n_embd,
            'block_size': model.config.block_size,
            'base_scale': model.config.base_scale,
            'bias': model.config.bias,
            'vocab_size': model.config.vocab_size,
            'dropout': model.config.dropout,
            'pad_token_id': model.config.pad_token_id
        },
        'iter_num': iter_num,
        'train_losses': train_losses,
        'val_losses': val_losses,
        'iterations': iterations
    }
    torch.save(checkpoint, filename)

def load_checkpoint(filename='checkpoint.pt', device='cuda'):
    checkpoint = torch.load(filename, map_location=device)
    config = EncoderDecoderConfig(**checkpoint['model_args'])
    model = EncoderDecoderGPT(config)
    model.load_state_dict(checkpoint['model'])
    model = model.to(device)

    optimizer = model.configure_optimizers(
        weight_decay=0.1 if not config.use_nGPT else 0.0,
        learning_rate=15e-4,
        betas=(0.9, 0.95),
        device_type='cuda' if 'cuda' in device else 'cpu'
    )
    optimizer.load_state_dict(checkpoint['optimizer'])

    return model, optimizer, checkpoint

def inference(model, tokenizer, input_text, max_length=128, device='cuda'):
    model.eval()
    with torch.no_grad():
        # Tokenize input
        encoder_input = tokenizer(input_text, return_tensors='pt',
                                padding='max_length',
                                max_length=model.config.block_size,
                                truncation=True).to(device)

        # Initialize decoder input with start token
        decoder_input = torch.tensor([[tokenizer.pad_token_id]]).to(device)

        # Generate tokens
        for _ in range(max_length):
            logits, _ = model(encoder_input.input_ids, decoder_input)
            next_token = torch.argmax(logits[:, -1, :], dim=-1)
            decoder_input = torch.cat([decoder_input, next_token.unsqueeze(0)], dim=1)

            if next_token.item() == tokenizer.eos_token_id:
                break

        return tokenizer.decode(decoder_input[0].tolist(), skip_special_tokens=True)

print("Loading and tokenizing dataset...")
dataset, tokenizer = get_owt_dataset(block_size)
dataset = dataset.train_test_split(test_size=test_size, seed=seed, shuffle=True)
dataset["val"] = dataset.pop("test")
print(f"Dataset loaded with {len(dataset['train'])} training samples and {len(dataset['val'])} validation samples")
vocab_size = tokenizer.vocab_size
pad_token_id = tokenizer.pad_token_id
def get_batch(split):
    """Get a batch of data with dynamic sequence lengths based on block_size"""
    data = dataset[split]
    idx = torch.randint(0, len(data), (batch_size,))

    encoder_max_len = block_size
    decoder_max_len = block_size // 2 - 1  # -1 for the shifted decoder input

    encoder_inputs = []
    decoder_inputs = []
    labels = []

    for i in idx:
        # Get sequences
        enc_input = torch.tensor(data[int(i)]['encoder_input_ids'])
        dec_input = torch.tensor(data[int(i)]['decoder_input_ids'])
        label = torch.tensor(data[int(i)]['labels'])

        # Padding is already handled in tokenize_and_chunk, but ensure correct shapes
        assert len(enc_input) == encoder_max_len, f"Encoder input length mismatch: {len(enc_input)} vs {encoder_max_len}"
        assert len(dec_input) == decoder_max_len, f"Decoder input length mismatch: {len(dec_input)} vs {decoder_max_len}"
        assert len(label) == decoder_max_len, f"Label length mismatch: {len(label)} vs {decoder_max_len}"

        encoder_inputs.append(enc_input)
        decoder_inputs.append(dec_input)
        labels.append(label)

    # Stack tensors into batches
    encoder_sequences = torch.stack(encoder_inputs).to(device)
    decoder_sequences = torch.stack(decoder_inputs).to(device)
    labels = torch.stack(labels).to(device)

    # Create attention masks (1 for tokens, 0 for padding)
    encoder_mask = (encoder_sequences != tokenizer.pad_token_id).to(device)
    decoder_mask = (decoder_sequences != tokenizer.pad_token_id).to(device)

    # Create causal mask for decoder self-attention
    causal_mask = torch.triu(torch.ones(decoder_max_len, decoder_max_len), diagonal=1).bool()
    causal_mask = causal_mask.to(device)

    return encoder_sequences, decoder_sequences, labels, encoder_mask, decoder_mask, causal_mask

def generate_square_subsequent_mask(sz):
    """Generate causal mask for decoder self-attention."""
    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))
    return mask

# Model initialization
model_args = dict(
    use_nGPT=use_nGPT,
    n_layer=n_layer,
    n_head=n_head,
    n_embd=n_embd,
    block_size=block_size,
    base_scale=base_scale,
    bias=bias,
    vocab_size=vocab_size,
    dropout=dropout,
    pad_token_id=pad_token_id
)

if init_from == 'scratch':
    config = EncoderDecoderConfig(**model_args)
    model = EncoderDecoderGPT(config)
elif init_from == 'resume':
    checkpoint = torch.load(os.path.join('./', 'ckpt.pt'))
    model_args = checkpoint['model_args']
    config = EncoderDecoderConfig(**model_args)
    model = EncoderDecoderGPT(config)
    model.load_state_dict(checkpoint['model'])
    iter_num = checkpoint['iter_num']

model.to(device)
optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)

if compile:
    model = torch.compile(model)

@torch.no_grad()
def estimate_loss():
    out = {}
    model.eval()
    for split in ['train', 'val']:
        losses = torch.zeros(eval_iters)
        progress_bar = tqdm(range(eval_iters), desc=f'Evaluating {split}', position=0, leave=True)
        for k in progress_bar:
            enc_seq, dec_seq, targets, enc_mask, dec_mask, causal_mask = get_batch(split)
            with ctx:
                logits, loss = model(enc_seq, dec_seq, targets, enc_mask, dec_mask, causal_mask)
            losses[k] = loss.item()
        out[split] = losses.mean()
    model.train()
    return out

def get_lr(it):
    if it < warmup_iters:
        return learning_rate * it / warmup_iters
    if it > lr_decay_iters:
        return min_lr
    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)
    assert 0 <= decay_ratio <= 1
    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))
    return min_lr + coeff * (learning_rate - min_lr)

def justnorm(x, idim=-1):
    dtype = x.dtype
    x = x.float()
    res = (x / x.norm(p=2, dim=idim, keepdim=True)).to(dtype=dtype)
    return res

def normalize_matrices():
    if not use_nGPT:
        return

    # Normalize encoder embeddings and layers
    model.encoder.wte.weight.data.copy_(justnorm(model.encoder.wte.weight.data, 1))
    for block in model.encoder.h:
        block.query.weight.data.copy_(justnorm(block.query.weight.data, 1))
        block.key.weight.data.copy_(justnorm(block.key.weight.data, 1))
        block.value.weight.data.copy_(justnorm(block.value.weight.data, 1))
        block.att_c_proj.weight.data.copy_(justnorm(block.att_c_proj.weight.data, 0))
        block.c_fc.weight.data.copy_(justnorm(block.c_fc.weight.data, 1))
        block.mlp_c_proj.weight.data.copy_(justnorm(block.mlp_c_proj.weight.data, 0))

    # Normalize decoder embeddings and layers
    model.decoder.wte.weight.data.copy_(justnorm(model.decoder.wte.weight.data, 1))
    for block in model.decoder.h:
        block.query.weight.data.copy_(justnorm(block.query.weight.data, 1))
        block.key.weight.data.copy_(justnorm(block.key.weight.data, 1))
        block.value.weight.data.copy_(justnorm(block.value.weight.data, 1))
        block.att_c_proj.weight.data.copy_(justnorm(block.att_c_proj.weight.data, 0))
        block.c_fc.weight.data.copy_(justnorm(block.c_fc.weight.data, 1))
        block.mlp_c_proj.weight.data.copy_(justnorm(block.mlp_c_proj.weight.data, 0))

    # Normalize output layer
    model.lm_head.weight.data.copy_(justnorm(model.lm_head.weight.data, 1))

# Training loop
if not os.path.isdir("plots"):
    os.makedirs("plots")
iter_num = 0 if init_from == 'scratch' else checkpoint['iter_num']
best_val_loss = float('inf')
t0 = time.time()
print("Starting Training...")
analyzer = ModelAnalyzer(model)
pbar = trange(iter_num, max_iters + 1, desc='Training', leave=True)
# Initialize lists to store losses for plotting
train_loss_plot = []
train_step_plot = []
for iter_num in pbar:

    if iter_num > max_iters_per_launch:
        break

    lr = get_lr(iter_num) if decay_lr else learning_rate
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

    if iter_num % eval_interval == 0:
        losses = estimate_loss()
        train_losses.append(losses['train'])
        val_losses.append(losses['val'])
        iterations.append(iter_num)
        pbar.set_description(f"train loss {losses['train']:.4f}, val loss {losses['val']:.4f}")
        if losses['val'] < best_val_loss:
            best_val_loss = losses['val']
            save_checkpoint(model, optimizer, iter_num, train_losses, val_losses, iterations, f'{wandb_run_name}_best_checkpoint.pt')
        if iter_num % (eval_interval * 10) == 0:
            save_checkpoint(model, optimizer, iter_num, train_losses, val_losses, iterations, f'{wandb_run_name}_checkpoint_{iter_num}.pt')
        if wandb_log:
            wandb.log({
                "iteration": iter_num,
                "val_loss_curve": losses['val'],
                "learning_rate": lr
            })

    if iter_num == 0 and eval_only:
        break

    enc_seq, dec_seq, targets, enc_mask, dec_mask, causal_mask = get_batch('train')
    for micro_step in range(gradient_accumulation_steps):
        with ctx:
            logits, loss = model(enc_seq, dec_seq, targets, enc_mask, dec_mask, causal_mask)
            loss = loss / gradient_accumulation_steps
        enc_seq, dec_seq, targets, enc_mask, dec_mask, causal_mask = get_batch('train')
        loss.backward()

    if grad_clip != 0.0:
        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
    optimizer.step()
    optimizer.zero_grad(set_to_none=True)

    if use_nGPT == 1:
        normalize_matrices()

    t1 = time.time()
    dt = t1 - t0
    t0 = t1

    if iter_num % log_interval == 0:
        lossf = loss.item() * gradient_accumulation_steps
        pbar.set_postfix(loss=f"{lossf:.4f}", lr=f"{lr:.6f}")
        if wandb_log:
            wandb.log({
                "train_loss_curve": lossf,
                "step": iter_num
            })
        # analyzer.analyze_model(use_nGPT=True, iter_num=iter_num, wandb_log=wandb_log)

    if time.time() - time.time() > time_limit_seconds:
        break

    if iter_num > max_iters:
        break

analyzer.analyze_model(use_nGPT=True, iter_num=iter_num, wandb_log=wandb_log)
save_checkpoint(model, optimizer, iter_num, train_losses, val_losses, iterations, f'{wandb_run_name}_final_checkpoint.pt')
print("Training complete.")
if wandb_log:
    wandb.finish()
def debug_forward_pass(model, dataset, tokenizer, device='cuda', sample_idx=3, dtype=torch.bfloat16):
    """
    Debug the forward pass of the encoder-decoder model with mixed precision support.

    Args:
        model: The EncoderDecoderGPT model
        dataset: The tokenized dataset
        tokenizer: The tokenizer used for the model
        device: The device to run the model on
        sample_idx: Index of the sample to test from dataset
        dtype: The dtype to use for the forward pass (default: torch.bfloat16)
    """
    model.eval()

    # Create autocast context manager
    ctx = torch.amp.autocast(device_type='cuda', dtype=dtype)

    with torch.no_grad(), ctx:
        # Get a single sample from dataset
        sample = dataset['train'][sample_idx]

        # Get the input sequences and convert to specified dtype
        encoder_input = torch.tensor(sample['encoder_input_ids']).unsqueeze(0).to(device)
        decoder_input = torch.tensor(sample['decoder_input_ids']).unsqueeze(0).to(device)
        labels = torch.tensor(sample['labels']).unsqueeze(0).to(device)

        # Create masks (keep masks in float32/bool)
        encoder_mask = (encoder_input != tokenizer.pad_token_id).to(device)
        decoder_mask = (decoder_input != tokenizer.pad_token_id).to(device)

        # Create causal mask for decoder
        seq_len = decoder_input.size(1)
        causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device)

        # Run forward pass
        try:
            logits, loss = model(encoder_input, decoder_input, labels,
                               encoder_mask, decoder_mask, causal_mask)

            # Get predictions
            predictions = torch.argmax(logits, dim=-1)

            print("\n=== Model Forward Pass Debug Information ===")

            print("\nDtype Information:")
            print(f"Model dtype: {next(model.parameters()).dtype}")
            print(f"Encoder input dtype: {encoder_input.dtype}")
            print(f"Decoder input dtype: {decoder_input.dtype}")
            print(f"Logits dtype: {logits.dtype}")

            print("\nInput Shapes:")
            print(f"Encoder input shape: {encoder_input.shape}")
            print(f"Decoder input shape: {decoder_input.shape}")
            print(f"Labels shape: {labels.shape}")

            print("\nMask Shapes:")
            print(f"Encoder mask shape: {encoder_mask.shape}")
            print(f"Decoder mask shape: {decoder_mask.shape}")
            print(f"Causal mask shape: {causal_mask.shape}")

            print("\nOutput Shapes:")
            print(f"Logits shape: {logits.shape}")
            print(f"Predictions shape: {predictions.shape}")

            # Convert to float32 for printing to avoid precision issues in display
            logits_float = logits.float()
            print("\nValue Ranges:")
            print(f"Logits min/max: {logits_float.min().item():.4f}, {logits_float.max().item():.4f}")
            print(f"Loss value: {loss.item():.4f}")

            print("\nToken Analysis:")
            print("Encoder Input:")
            print(f"Input text: {tokenizer.decode(encoder_input[0].tolist())}")
            print(f"Unique tokens: {len(torch.unique(encoder_input))}")
            print(f"Contains pad token: {(encoder_input == tokenizer.pad_token_id).any().item()}")

            print("\nDecoder Input:")
            print(f"Input text: {tokenizer.decode(decoder_input[0].tolist())}")
            print(f"Unique tokens: {len(torch.unique(decoder_input))}")
            print(f"Contains pad token: {(decoder_input == tokenizer.pad_token_id).any().item()}")

            print("\nPredictions:")
            print(f"Predicted text: {tokenizer.decode(predictions[0].tolist())}")
            print(f"Unique predicted tokens: {len(torch.unique(predictions))}")

            # Check for potential issues
            print("\nPotential Issues:")
            if torch.isnan(logits).any():
                print("WARNING: NaN values detected in logits")
            if torch.isinf(logits).any():
                print("WARNING: Inf values detected in logits")
            if len(torch.unique(predictions)) < 5:
                print("WARNING: Very low variety in predicted tokens")
            if (predictions == tokenizer.pad_token_id).all():
                print("WARNING: All predictions are pad tokens")

            return {
                'encoder_input': encoder_input,
                'decoder_input': decoder_input,
                'logits': logits,
                'predictions': predictions,
                'loss': loss
            }

        except RuntimeError as e:
            print("\n=== Error in Forward Pass ===")
            print(f"RuntimeError: {str(e)}")
            print("\nModel Parameter dtypes:")
            for name, param in model.named_parameters():
                print(f"{name}: {param.dtype}")
            raise e
debug_results = debug_forward_pass(model, dataset, tokenizer, dtype=torch.bfloat16)